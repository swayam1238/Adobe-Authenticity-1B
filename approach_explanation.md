Methodology for Persona-Driven Document Intelligence
Our solution for the "Connect What Matters" challenge is architected around a sophisticated semantic search pipeline, designed to function as a specialized, AI-powered research assistant. The primary goal is to transcend the limitations of traditional keyword matching and instead comprehend the contextual and thematic relevance of document sections in relation to a user's specific role and task. In a world of information overload, simply finding documents is not enough; the true challenge is to pinpoint the exact information within those documents that matters most. This approach allows the system to understand user intent, delivering a highly-focused and accurately prioritized set of insights that saves users valuable time and cognitive load.

Core Methodology: Semantic Search via Text Embeddings
The foundation of our system is the conversion of unstructured text into meaningful numerical representations, or "embeddings." By mapping both the user's query and the document content into a shared high-dimensional vector space, we can perform relevance calculations based on semantic proximity rather than lexical overlap. This process unfolds in several key stages:

1. Persona-Centric Query Formulation:
The system begins by synthesizing the persona and job_to_be_done fields from the input JSON into a single, descriptive query. For instance, "As a PhD Researcher in Computational Biology, I need to prepare a comprehensive literature review focusing on methodologies." This combined query provides a rich contextual anchor, ensuring our search is guided by the user's specific professional lens and immediate objective, not just a few isolated keywords.

2. Document Ingestion and Granular Chunking:
Next, we process the provided PDF collection. Using the efficient PyMuPDF library, we extract the raw text content from each document. Crucially, we do not treat documents as monolithic blocks of text. Instead, we segment them into smaller, more coherent chunks, primarily at the paragraph level. This "chunking" strategy is vital for effective semantic analysis. It allows for a more granular and precise comparison against the user's query, preventing relevant details from being diluted within large, thematically diverse sections of text. This ensures that even a single, highly relevant paragraph can be identified and surfaced.

3. Semantic Embedding with Sentence-Transformers:
This stage is the core of our intelligent engine. We employ the all-MiniLM-L6-v2 model from the sentence-transformers library. This model was specifically chosen for its exceptional balance of performance, speed, and size, making it ideal for the hackathon's constraints. It is a lightweight transformer model (<100MB) that runs efficiently on a CPU. It has been trained on a massive corpus of text to understand sentence-level semantics, allowing it to grasp concepts, analogies, and context. The model processes both the persona query and every document chunk, converting them into 384-dimensional vectors. In this vector space, texts with similar meanings are positioned closely together.

4. Relevance Scoring with Cosine Similarity:
With all text represented as vectors, we can mathematically determine relevance. We use Cosine Similarity to measure the angular distance between the persona query vector and each paragraph vector. A score close to 1.0 indicates a very strong semantic alignment. This metric is superior to simple distance measures because it focuses on the orientation (i.e., the "topic") of the vectors, not just their proximity, making it robust to variations in sentence length and phrasing.

5. Global Ranking and Output Generation:
Finally, every paragraph from all documents, now associated with a relevance score, is placed into a single, globally ranked list. This global ranking is a critical feature, as it ensures that the most pertinent information rises to the top, regardless of which source document it originated from. The highest-scoring paragraphs are then selected and formatted into the required extracted_section and sub-section_analysis fields in the final JSON output, directly populating the importance_rank field and providing the user with a concise, prioritized, and highly relevant summary tailored to their specific needs.
